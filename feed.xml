<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://herman-wu.github.io/blogs/feed.xml" rel="self" type="application/atom+xml" /><link href="https://herman-wu.github.io/blogs/" rel="alternate" type="text/html" /><updated>2020-05-26T19:47:11-05:00</updated><id>https://herman-wu.github.io/blogs/feed.xml</id><title type="html">Herman’s Notebook</title><subtitle>Here is the repository of notes that I would like to remember and share</subtitle><entry><title type="html">Lessons learned from building a large scale historical data analysis system using Azure Data Explorer - Part 2</title><link href="https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/25/Lession-Learn-LargeScale-ADX-part2.html" rel="alternate" type="text/html" title="Lessons learned from building a large scale historical data analysis system using Azure Data Explorer - Part 2" /><published>2020-05-25T00:00:00-05:00</published><updated>2020-05-25T00:00:00-05:00</updated><id>https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/25/Lession-Learn-LargeScale-ADX-part2</id><content type="html" xml:base="https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/25/Lession-Learn-LargeScale-ADX-part2.html">&lt;p&gt;[&lt;em&gt;This is the part II of the topic, you can check &lt;a href=&quot;https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/05/21/Lession-Learn-LargeScale-ADX-part1.html&quot;&gt;Part I&lt;/a&gt; if you haven’t.&lt;/em&gt;]&lt;/p&gt;

&lt;p&gt;I have mentioned &lt;a href=&quot;https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/05/21/Lession-Learn-LargeScale-ADX-part1.html&quot;&gt;5 basic lessons&lt;/a&gt; I learned from my recent project that has hundreds of terabytes data. In this &lt;strong&gt;part II&lt;/strong&gt; I would like to share a few more advanced lessons.&lt;/p&gt;

&lt;h5 id=&quot;lesson-6-consider-guiding-users-to-submit-the-right-queries-and-think-about-having-some-data-process-running-on-the-client-side&quot;&gt;Lesson 6 Consider guiding users to submit the right queries and think about having some data process running on the client-side&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;https://azure.microsoft.com/en-in/services/data-explorer/&quot;&gt;Azure Data Explorer&lt;/a&gt;(ADX) is designed to process a huge amount of data. It can efficiently handle hundreds of terabytes data or even petabytes data. Data is a very valuable asset especially when you have a lot of them. These data can support users to find hidden business trends, detect anomaly events, identify correlation things from these data.&lt;/p&gt;

&lt;p&gt;However with so much data in your system’s back yard, you also need to make sure users will access them in the right way because users might not have a good sense of how much data they are trying to process. So we should guide and prevent users from unconsciously trying to retrieve 100 gigabytes of data to their web browser or trying to get 1 million records to their client just for showing a line chart. Helping users to use aggregation and return data in just enough granularity for their business needs can largely reduce system workload and improve performance.&lt;/p&gt;

&lt;p&gt;Also you should consider using the user’s client to share some data process loading of ADX. For example, users might want to sort the result by some specific columns, this can be easily implemented on the client-side. It’s also easier to do data paging in client slides then resubmit queries for each page.&lt;/p&gt;

&lt;p&gt;In ADX it provides some mechanisms such as &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/concepts/querylimits#limit-on-result-set-size-result-truncation&quot;&gt;result set size&lt;/a&gt;, &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/concepts/querylimits#limit-on-request-execution-time-timeout&quot;&gt;request execution time&lt;/a&gt; to prevent system resource been occupied by some bad queries. You can also use these mechanisms to prevent some queries to take too many resources from the system or grant more resources to some special queries.&lt;/p&gt;

&lt;h5 id=&quot;lesson-7-check-some-advance-table-policy&quot;&gt;Lesson 7 Check some advance table policy&lt;/h5&gt;

&lt;p&gt;To further provide better query performance, ADX now provides some new more advanced configuration in Table policies such as &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/partitioningpolicy&quot;&gt;Data partitioning policy&lt;/a&gt; and &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/roworder-policy&quot;&gt;RowOrder policy&lt;/a&gt;. If you need to improve query response time, they are options you can try. But using them carefully, &lt;strong&gt;they will increase data ingestion time and consume more computing resources&lt;/strong&gt;. Also, partition has some side effect on extents management and need more resources to run the policy.&lt;/p&gt;

&lt;p&gt;The other consideration is the choice between putting data in different tables or different databases. This choice will impact the following areas in system design:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Data Access Control&lt;/li&gt;
  &lt;li&gt;Admin node workload&lt;/li&gt;
  &lt;li&gt;Data sharing mechanism&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Users should consider putting data in different databases when you want to have more flexibility to manage and share data. Also when the data volume is big, having multiple databases can enjoy the benefit of having different Admin nodes for each database and then have more resources to maintaining data metadata and perform transactions.&lt;/p&gt;

&lt;h5 id=&quot;lesson-8-check-server-loading-and-very-very-carefully-tuning-some-of-them-if-needed&quot;&gt;Lesson 8 Check Server loading and very very carefully tuning some of them if needed.&lt;/h5&gt;

&lt;p&gt;To handle data ingestion and query workload, ADX has several mechanisms to balance the resources used to support different operation and maintenance workload.&lt;/p&gt;

&lt;p&gt;For data management operations, you can use &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/capacitypolicy&quot;&gt;.show capacity&lt;/a&gt; to quickly show the resources utilization of these core capabilities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-25-Lession-Learn-LargeScale-ADX-part2/show_capacity.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In most cases the official recommendation is &lt;strong&gt;just leave the setting as is, the default setting should be able to handle most of the situations&lt;/strong&gt; and they will keep each resource utilization balanced. If in some cases if you thought you really need to change these values, it’s also recommended to at least check and ask in &lt;a href=&quot;https://stackoverflow.com/questions/tagged/kusto&quot;&gt;stackoverflow&lt;/a&gt; to have some experts to double verify it.&lt;/p&gt;

&lt;p&gt;Also you might also want to check the Extents number and its growth in your system. Extents are the core data allocation unit within ADX, ADX will try to organize it in the best way to fulfill both data ingestion needs and data query needs. If for some reason too much extends are created, it will increases the loading of ADX admin node and potential will impact system performance. For a large system it’s a good practice to keep an eye on it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-25-Lession-Learn-LargeScale-ADX-part2/total_extents.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;lesson-9-optimize-the-kql-query-plan-for-the-long-queries-and-review-cache-policy&quot;&gt;Lesson 9 Optimize the KQL query plan for the long queries and review cache policy&lt;/h5&gt;
&lt;p&gt;Though we mentioned how different query syntax could impact query performance in  &lt;a href=&quot;https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/05/21/Lession-Learn-LargeScale-ADX-part1.html&quot;&gt;Understand and test KQL query performance session of Part I&lt;/a&gt;, here I want to talk about KQL query plan.&lt;/p&gt;

&lt;p&gt;In Kusto Explorer, there is a build-in tool named Query Analyzer which provides extra information on how your KQL runs. You can use them to understand how the query actually being executed, if your query can run in parallel on all the nodes, if the query filter efficiently reduces data retrieval volumes or if the data join.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-25-Lession-Learn-LargeScale-ADX-part2/execprofile.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-25-Lession-Learn-LargeScale-ADX-part2/reloptree.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Also by design initially (before the cluster is running) all the data are stored on cold storage (Azure Blob storage). When the cluster starts, cluster nodes will load all these hot data (defined by &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/cachepolicy&quot;&gt;Cache policy&lt;/a&gt;) data into local SSD and memory so they become hot data and can be quickly accessed. Review the cache hit rate of popular queries and check if the cache policy is properly defined can potentially have a good boost of performance.&lt;/p&gt;

&lt;h5 id=&quot;lesson-10-review-security-setting&quot;&gt;Lesson 10 Review Security Setting&lt;/h5&gt;

&lt;p&gt;Last but not least, Security. ADX can use both Azure AD and Microsoft Account (MSAs) as the identity providers. And we also need to have a plan for user authentication and &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/access-control/how-to-provision-aad-app&quot;&gt;application authentication&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are different &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/access-control/role-based-authorization&quot;&gt;security roles&lt;/a&gt; in ADX. It’s good to review the security setting in your system and make sure you have separation of concerns for your account and security planning.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Azure Data Explorer is a very powerful tool for analyzing historical log or telemetries data. In many cases we saw it provide a more cost-effective and more powerful query tool to fulfill users’ business needs.&lt;/p&gt;

&lt;p&gt;Above are 10 lessons I thought are important when implementing a large scale data analysis platform when using Azure Data Explorer. The best way to understand the detail of them is still read through the official documents. But these lessons might provide you a quick bird’s-eye view of what you should check and look.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Reference]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Azure-Samples/kusto-high-scale-ingestion/blob/master/processing/README.md&quot;&gt;- kusto-high-scale-ingestion&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://azure.microsoft.com/en-ca/resources/azure-data-explorer/&quot;&gt;- Azure Data Explorer technical white paper&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://yonileibowitz.github.io/kusto.blog/blog-posts/update-policies.html&quot;&gt;- Update policies for in-place ETL in Kusto (Azure Data Explorer)&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">[This is the part II of the topic, you can check Part I if you haven’t.]</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" /><media:content medium="image" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Lessons learned from building a large scale historical data analysis system using Azure Data Explorer - Part 1</title><link href="https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/21/Lession-Learn-LargeScale-ADX-part1.html" rel="alternate" type="text/html" title="Lessons learned from building a large scale historical data analysis system using Azure Data Explorer - Part 1" /><published>2020-05-21T00:00:00-05:00</published><updated>2020-05-21T00:00:00-05:00</updated><id>https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/21/Lession-Learn-LargeScale-ADX-part1</id><content type="html" xml:base="https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/21/Lession-Learn-LargeScale-ADX-part1.html">&lt;p&gt;Recently I had an opportunity to participate in another data project that also uses &lt;a href=&quot;https://azure.microsoft.com/en-in/services/data-explorer/&quot;&gt;Azure Data Explorer&lt;/a&gt;(ADX) as the core data process and store engine. In this project we used ADX to ingest and process more than half of petabytes data. Like most projects we were under some time and resource constraints, and also encountered a few unexpected technical challenges due to the constraints. Though we couldn’t implement the system using the best-optimized architecture (it will take too much time than the project was allowed), we still managed to achieve the project goal. It’s an exciting and fun journey and here are a few lessons we learned.&lt;/p&gt;

&lt;h5 id=&quot;lesson-1-select-proper-sku&quot;&gt;Lesson 1 Select proper SKU&lt;/h5&gt;

&lt;p&gt;There are couples different &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/manage-cluster-choose-sku&quot;&gt;SKU options for ADX&lt;/a&gt;, some are more CPU optimized like D-Series (D-series, Ds-series) VM, they have more powerful CPU; some are more storage optimized like Ls-Serious VM, they are equipped with larger SSD to achieve more I/O performance. &lt;em&gt;Have a testing plan to test the key user query patterns on these different type of VMs and check which one is best for your query workload can benefit the project in the long run.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-21-Lession-Learn-LargeScale-ADX-part1/ADX_SKU.JPG&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;lesson-2-check-different-ingestion-options&quot;&gt;Lesson 2 Check different ingestion options.&lt;/h5&gt;

&lt;p&gt;In Azure Data Explorer, it supports several different ingestion solutions, the decision will depend on the purpose and stage of your development. You can check &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/data-ingestion/#ingestion-methods&quot;&gt;here&lt;/a&gt; for detail information of these solutions.&lt;/p&gt;

&lt;p&gt;It’s better to read through the official document, understand their differences before making a decision. Meanwhile, here are a few thumb rules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For query testings, verifying scripts, tables, you can use &lt;strong&gt;Inline ingestion (push)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For ad-hoc feature engineering, data cleaning, you can use &lt;strong&gt;Ingest from query&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For ingestion testing, create some volumes of data, you can use &lt;strong&gt;Ingest from storage (pull)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For production ingestion pipeline testing, I normally will use &lt;strong&gt;Queued ingestion&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to the above basic ingestion options, you can also check the following options based on your scenario and environment.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/data-ingestion/eventgrid&quot;&gt;Ingest from storage using Event Grid subscription&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/data-ingestion/eventhub&quot;&gt;Ingest from Event Hub&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/data-ingestion/iothub&quot;&gt;Ingest from IoT Hub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And there is a new ingestion option &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/ingest-data-one-click&quot;&gt;One-Click Ingestion&lt;/a&gt; which are just been announced in &lt;a href=&quot;https://mybuild.microsoft.com/&quot;&gt;Microsoft Build 2020&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Eeek, a lot of choices. :p&lt;/p&gt;

&lt;h5 id=&quot;lesson-3-have-a-clean-ingestion-pipeline&quot;&gt;Lesson 3 Have a clean ingestion pipeline&lt;/h5&gt;

&lt;p&gt;Normally when trying to ingest data into a data repository, we might need to do some data pre-process such as check file format, clean dirty data, do a few data transformation, etc. Azure Data Explorer provides some of these capabilities through &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/functions/user-defined-functions&quot;&gt;User-defined function&lt;/a&gt; and &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/update-policy&quot;&gt;update policy&lt;/a&gt;. You can use these mechanisms to quickly perform some data pre-process tasks within ADX without setup extra computing services to handle it.&lt;/p&gt;

&lt;p&gt;While these are convenient ways to massage data, it will occupy ADX’s resources and potentially introduce more data fragmentation. There are complex mechanisms within ADX to optimize the resources it has, maintains and organize data in its storage and keep the system in a healthy status.&lt;/p&gt;

&lt;p&gt;Under the condition that data ingestion volume is big, these data pipeline activities could impact the resource available for ADX to handle queries or do internal housekeeping tasks. You might need to carefully monitor ADX status and do a few fine tunes on its configuration. While I did use these mechanisms for other smaller-scale projects and love it, &lt;em&gt;it is still a better practice just to keep the data pre-process tasks outside of ADX in large scale project, at least before you are very familiar each internal mechanisms within ADX.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Data Factory, Databricks, Azure Functions/App services, AKS, HDInsight provide good foundational capabilities to pre-process data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-21-Lession-Learn-LargeScale-ADX-part1/Ingest.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://github.com/Herman-Wu/ADXAutoFileIngestion&quot;&gt;my git project&lt;/a&gt; I shared some codes that I used Azure Functions to do Queued ingestion.&lt;/p&gt;

&lt;h5 id=&quot;lesson-4-evaluate-the-horizontal-scale--of-servers-needed&quot;&gt;Lesson 4 Evaluate the horizontal scale (# of servers) needed&lt;/h5&gt;

&lt;p&gt;When planning system roll-out, a solid estimation of the number of servers needed and a well-estimated expansion plan for the future is important. It can also help save costs by preventing under-utilization and provide valuable information for system design. System &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/manage-cluster-horizontal-scaling&quot;&gt;scale out/ horizontal scaling&lt;/a&gt; is one of the core capabilities that we can make sure the system can be adaptive to the workload and provide just enough resource to the users. In our test, one of the key ADX features that users love is it can provide almost linear performance growth when scaling out. ADX also provides non-destructive services when scaling out.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/media/manage-cluster-horizontal-scaling/manual-scale-method.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It’s suggested that you should run a few workload simulations and test about how the scale-out can increase your system capabilities.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-21-Lession-Learn-LargeScale-ADX-part1/QueryPerf01.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ACI and AKS can be helpful if you want to simulate the system workload.&lt;/p&gt;

&lt;h5 id=&quot;lesson-5-understand-and-test-kql-query-performance&quot;&gt;Lesson 5 Understand and test KQL query performance&lt;/h5&gt;

&lt;p&gt;One of the key strengths of ADX is its powerful query language &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/query/&quot;&gt;Kusto Query Language&lt;/a&gt; (KQL). Like most other data query languages, some query operators in KQL are similar, give you the same result but could have a huge difference in performance.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It’s always good the validate what’s your key query scenarios and try how different query syntax impact the query performance.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-21-Lession-Learn-LargeScale-ADX-part1/KustoExpQuery.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can review the query performance using &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/tools/kusto-explorer&quot;&gt;Kusto.Explorer tool&lt;/a&gt; or &lt;a href=&quot;https://dataexplorer.azure.com/&quot;&gt;ADX Web UI&lt;/a&gt;. You can also use &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/kusto/management/queries&quot;&gt;.show queries&lt;/a&gt; operator to review the performance of historical queries.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-05-21-Lession-Learn-LargeScale-ADX-part1/ShowQueries.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;.. to be continued&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://herman-wu.github.io/blogs/azure%20data%20explorer/kusto/data/kql/azure/2020/05/25/Lession-Learn-LargeScale-ADX-part2.html&quot;&gt;Lessions learned from buiding a large scale historical data analysis system using Azure Data Explorer - Part 2&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Recently I had an opportunity to participate in another data project that also uses Azure Data Explorer(ADX) as the core data process and store engine. In this project we used ADX to ingest and process more than half of petabytes data. Like most projects we were under some time and resource constraints, and also encountered a few unexpected technical challenges due to the constraints. Though we couldn’t implement the system using the best-optimized architecture (it will take too much time than the project was allowed), we still managed to achieve the project goal. It’s an exciting and fun journey and here are a few lessons we learned.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" /><media:content medium="image" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Troubleshooting Azure Data Explorer (Kusto) cross-tenant access issues</title><link href="https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/03/17/TroubleShootingADXLoginIssues.html" rel="alternate" type="text/html" title="Troubleshooting  Azure Data Explorer (Kusto) cross-tenant access issues" /><published>2020-03-17T00:00:00-05:00</published><updated>2020-03-17T00:00:00-05:00</updated><id>https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/03/17/TroubleShootingADXLoginIssues</id><content type="html" xml:base="https://herman-wu.github.io/blogs/azure%20data%20explorer%20(kusto)/data/2020/03/17/TroubleShootingADXLoginIssues.html">&lt;h5 id=&quot;azure-data-explorer-introduction&quot;&gt;Azure Data Explorer Introduction&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/data-explorer-overview&quot;&gt;Azure Data Explorer (ADX, aka Kusto)&lt;/a&gt; is a very powerfully log/historical data analysis platform provided by Microsoft that powers several key Azure services such as Application Insight, Azure Monitor, Time Series insight. It is designed to handle huge amounts of historical data and can ingest and process Peta-bytes of data every day with little efforts to set up the infrastructure. On February 7, 2019, Microsoft GA the service to customers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/ADXOverview.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One of the features that I particularly like is its query language KQL (Kusto Query Language), KQL combines the concept of SQL query and data pipeline. In real project experience, it is very powerful and saved me a lot of time to get the query result in the structure that my projects need. You can check &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/query/tutorial?pivots=azuredataexplorer&quot;&gt;this official tutorial&lt;/a&gt; that introduces KQL’s key concept and following is an example about how to query data 12 days ago and do count aggregation very 30 minutes. It’s a very popular bin count pattern when analyzing data on time dimension. In the query we use &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/query/mvexpandoperator&quot;&gt;“mv-expand”&lt;/a&gt; operator to make sure there is still a record presents the 0 count even the system has no data in that 30 minutes range. “mv-expand” is also very useful when you are parsing and expanding JSON data.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let StartTime=ago(12d);
let StopTime=ago(11d);
T
| where Timestamp &amp;gt; StartTime and Timestamp &amp;lt;= StopTime 
| summarize Count=count() by bin(Timestamp, 30m)
| union ( // 1
  range x from 1 to 1 step 1 // 2
  | mv-expand Timestamp=range(StartTime, StopTime, 30m) to typeof(datetime) // 3
  | extend Count=0 // 4
  )
| summarize Count=sum(Count) by bin(Timestamp, 30m) // 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/kqlqueryresult.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also easily generate a graphic chart to visualize your query result through &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/query/renderoperator?pivots=azuredataexplorer&quot;&gt;“render”&lt;/a&gt; operator. In the previous query, you can add “| render timechar” to generate the following graph which represents the trend of how many records we have every 30 mins eleven days ago.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;|render timechart 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/kqlquerygraph.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For data consumers ADX also provides various client tool that users can use to create different kind of query, graphic chart and dashboard. The tool that support ADX includes :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/web-query-data&quot;&gt;ADX WebUI&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/tools/kusto-explorer&quot;&gt;Kusto Desktop Client tool&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;PowerBI&lt;/li&gt;
  &lt;li&gt;Excel&lt;/li&gt;
  &lt;li&gt;Jupyter Notebook(&lt;a href=&quot;https://github.com/microsoft/jupyter-Kqlmagic&quot;&gt;using KQLMagic extension&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/data-explorer/grafana&quot;&gt;Grafana&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Azure/azure-kusto-spark&quot;&gt;Spark&lt;/a&gt;   .&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;azure-data-explorer-access-control&quot;&gt;Azure Data Explorer Access Control&lt;/h5&gt;

&lt;p&gt;In the access control part, ADX supports user authentication through Microsoft Accounts (MSAs) and Azure AD account. Microsoft Account is non-organizational user accounts, these accounts normally use email like hotmail.com, live.com, outlook.com. Azure AD account is created through Azure AD or another Microsoft cloud service such as Office 365. It will be tight to an Azure AD tenant and is the preferred method for authenticating to ADX.  Most enterprise users should use AAD account for authentication. Here has more information about &lt;a href=&quot;https://docs.microsoft.com/zh-tw/azure/kusto/management/access-control/&quot;&gt;ADX access control&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Like most Azure services, you can manage user accounts and their access to ADX through “Access control” function within Azure Portal.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/ADXAccessControl.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The other way to manage it is through KQL query. You can run the following command to check the accounts and roles that can access ADX database.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;Database&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;principals&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can read ADX &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/management/security-roles&quot;&gt;Security roles management&lt;/a&gt; session to understand more about using  KQL to manage user access control.&lt;/p&gt;

&lt;p&gt;ADX authentication is also the part I would like to share a few troubleshooting tips which  I learned from projects.&lt;/p&gt;

&lt;h5 id=&quot;azuer-data-explorer-cross-tenant-access-issue&quot;&gt;Azuer Data Explorer cross-tenant access issue&lt;/h5&gt;

&lt;p&gt;Ideally if you login your PC with Azure AD account that in the same tenant of the Azure subscription which been used to create the ADX cluster, then everything should work good and you can just management user access in Azure Portal. However it’s not always the case, users can come from different organizations and partners. Here are a few ways we used to check and fix the issues.&lt;/p&gt;

&lt;h5 id=&quot;the-problem&quot;&gt;The problem:&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;Grant a user to access ADX in Azure Portal UI. And the user can assess ADX in Azure portal. But he/she but couldn’t access it in &lt;a href=&quot;(https://docs.microsoft.com/en-us/azure/data-explorer/web-query-data)&quot;&gt;ADX Web UI&lt;/a&gt; and &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/kusto/tools/kusto-explorer&quot;&gt;Kusto Explorer&lt;/a&gt;, PowerBI, Excel or other client tools.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What happened is when you grant a new user to access ADX, if the user’s account comes from a different tenant, in ADX it will create a new Principle Object Id in its tenant. If the user access ADX in Azure portal, the user’s account already switches to the right tenant so there is no problem accessing ADX. But if users from different tenant try to use other client tools, these client tools will use default tenant and which might not match the tenant that ADX is using.&lt;/p&gt;

&lt;h5 id=&quot;how-to-fix-the-issue&quot;&gt;How to fix the issue&lt;/h5&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Solution A&lt;/strong&gt;: Force ADX WebUI and Kusto Explorer to use not ADX’s tenant&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ADX WebUI&lt;/p&gt;

    &lt;p&gt;Default ADX WebUI has URL like&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;https://dataexplorer.azure.com/clusters/[cluster name].[data center]&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;You can force it to recognize a user’s login tenant by add &amp;amp;tenant=[tenant id] to the URL. So it will look like&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;https://dataexplorer.azure.com/clusters/[cluster name].[data center]?tenant=[tenant id]&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kusto Explorer Client&lt;/p&gt;

    &lt;p&gt;Instead of default connection by specifying ADK cluster URL, You need to use advanced query.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/KustoExpConn.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The connection string will be like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  Data Source=https://[Cluster Name].[Data Center].kusto.windows.net;AAD Federated Security=True;AAD User ID=[User's AAD account(E-mail)];Authority Id=[User's AAD account tenant ID ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Solution B&lt;/strong&gt;: Grant user using ‘right’ tenant id and account id&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As said by default user granted in Azure portal will using ADX’s tenant id and create a new account object id. If you want to add a user from a different tenant, the suggested way will be to grant users using KQL.&lt;/p&gt;

&lt;p&gt;You can grant a new user with different roles like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-kql&quot;&gt;.add database [Database Name] [Role Name]  ('aaduser=[User AAD account id];[User AAD tenant id]') 'Notes for the account, eg. User Name'

&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Get AAD account object id &amp;amp; tenant id using Azure CLI&lt;/p&gt;

    &lt;p&gt;To get user’s AAD account object id, you can use Azure CLI command :&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  az ad signed-in-user show 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To get the user’s tenant ID, you can use Azure CLI command :&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  az account list 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Get AAD account object id &amp;amp; tenant id in Azure portal&lt;/p&gt;

    &lt;p&gt;You can also find AAD account object id &amp;amp; tenant id in Azure Active Directory service of  Azure portal.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2020-03-17-TroubleShootingADXLoginIssues/AAD.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Get AAD account object id &amp;amp; tenant id in ADX Web UI&lt;/p&gt;

    &lt;p&gt;If you login using ADX Web UI, actually the error message contains the AAD user account id and tenant id. The message will be looks like following&lt;/p&gt;

    &lt;p&gt;&lt;em&gt;Error message : 
action Principal ‘aaduser=[&lt;strong&gt;AAD accound id&lt;/strong&gt;];[ &lt;strong&gt;AAD tenant id&lt;/strong&gt; ]’ is not authorized to perform operation&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;It’s another easy way to get the information you needed.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
ADX is a very powerful platform that provides interactive analysis capabilities which can handle huge amount of historical log data with little infrastructure maintenance efforts. Because most enterprises use Azure AD to grant users access, helping these tips can save you sometime when you have cross tenant access requirements.&lt;/p&gt;</content><author><name></name></author><summary type="html">Azure Data Explorer Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" /><media:content medium="image" url="https://azurecomcdn.azureedge.net/cvt-ee71595d3667788def73479da1629d673313a0b081e460fc596839b82f34a2df/images/page/services/machine-learning/mlops/steps/mlops-slide1-step3.svg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Test</title><link href="https://herman-wu.github.io/blogs/2019/03/03/Test.html" rel="alternate" type="text/html" title="Test" /><published>2019-03-03T00:00:00-06:00</published><updated>2019-03-03T00:00:00-06:00</updated><id>https://herman-wu.github.io/blogs/2019/03/03/Test</id><content type="html" xml:base="https://herman-wu.github.io/blogs/2019/03/03/Test.html">&lt;p&gt;Test Images&lt;/p&gt;

&lt;p&gt;This is a Test&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://Herman-Wu.github.io/blogs/assets/img/2019-03-03-Test/media/image1.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Herman-Wu/blogs/blob/master/images/diagram.png?raw=true&quot;&gt;https://github.com/Herman-Wu/blogs/blob/master/images/diagram.png?raw=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/img/2019-03-03-Test/media/image2.png&quot; alt=&quot;Screenshot&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Test Images</summary></entry></feed>